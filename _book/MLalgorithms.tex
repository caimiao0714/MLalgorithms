\documentclass[fontset=fandol,zihao=false,scheme=chinese,heading=true,UTF8]{ctexbook}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\PassOptionsToPackage{dvipsnames}{xcolor}
\RequirePackage{xcolor} % [dvipsnames]
%\usepackage{xcolor}

\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[b5paper,paperwidth=17.6cm,paperheight=25cm,tmargin=3.2cm,bmargin=3.2cm,lmargin=2.5cm,rmargin=2.5cm]{geometry}
\usepackage[unicode=true]{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{
            pdftitle={Machine learning Algorithms},
            pdfauthor={蔡苗},
            colorlinks=true,
            linkcolor=Maroon,
            citecolor=Blue,
            urlcolor=Blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{long table}}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{longtable}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}
\usepackage{style/lshort-zn-cnMiao}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\newenvironment{dedication}
{
   \cleardoublepage
   \thispagestyle{empty}
   \vspace*{\stretch{1}}
   \hfill\begin{minipage}[t]{0.66\textwidth}
   \raggedright
}
{
   \end{minipage}
   \vspace*{\stretch{3}}
   \clearpage
}

\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

%\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\frontmatter


\title{{\fontsize{26}{30}\selectfont \textbf{Machine learning Algorithms}}}
\author{蔡苗\footnote{Department of Epidemiology and Biostatistics, College for Public Health and Social Justice, Saint Louis University. Email: \url{miao.cai@slu.edu}}}
\date{2019-04-20}

\begin{document}
\maketitle

\begin{dedication}
感谢我的家人的支持。
\end{dedication}

\section*{Acknowledgement}

I want to thank my mentor.

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures



\hypertarget{preface}{%
\chapter{Preface}\label{preface}}

This book works as a notebook to summarize the algorithms used in Bayesian inference and machine learning.

\mainmatter

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{discrete-optimization}{%
\chapter{Discrete optimization}\label{discrete-optimization}}

Most of the concepts are explain in Chapter 4 Numerical Computation from the Deep Learning book \url{https://www.deeplearningbook.org/contents/numerical.html}.
The other useful resource is \href{http://cs231n.github.io/}{CS231m Convolutional Neural Networks} for Visual Recognition by Stanford University

The \textbf{objective function} allows us to measure how ``good'' any given solution to the problem is.
We seek to maximize or minimize the objective function.

\textbf{Derivative/gradient} based methods keep going ``uphill'' until they are at the top of the h

\hypertarget{heuristic-and-metaheuristic-methods}{%
\section{Heuristic and metaheuristic methods}\label{heuristic-and-metaheuristic-methods}}

\begin{quote}
a \textbf{heuristic} is a technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution.
\end{quote}

\begin{quote}
Wikipedia
\end{quote}

Heuristic methods do not guarantee to find the global optimal solution (best solution)!
Instead, they seek to find \textbf{a best available solution, given the resource spent looking for it}.
A \textbf{heuristic method} is \textbf{geared towards a specific problem}.

\begin{quote}
a \textbf{metaheuristic} is a higher-level procedure or heuristic designed to find, generate, or select a heuristic (partial search algorithm) that may provide a sufficiently good solution to an optimization problem, especially with incomplete or imperfect information or limited computation capacity. Metaheuristics sample a set of solutions which is too large to be completely sampled. Metaheuristics may make few assumptions about the optimization problem being solved, and so they may be usable for a variety of problems
\end{quote}

\begin{quote}
-- Wikipedia
\end{quote}

A metaheuristic method is like a heuristic, but generalizable to a broad class of problems.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Genetic Algorithms (Holland -- 1975)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Natural selection / genetics based. Popular method.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Simulated Annealing (Kirpatrick -- 1983)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Metallurgy annealing, find lowest energy level!
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Particle Swarm Optimization (Eberhart Kennedy - 1995)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Based on insect behavior, swarming towards optimal location (food). Less common in discrete spaces. originally proposed for continuous spaces.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Tabu Search (Al-Sultan -- 1999)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Search for best neighborhood solution, then find new neighborhood. Prior neighborhoods are forbidden (tabu)
\end{itemize}

General meta-heuristics traits

\begin{itemize}
\tightlist
\item
  Evaluate many potential optimal solutions.
\item
  Evaluate the fitness of each solution based on a cost (objective) function.
\item
  Use some concept of stochastic (random) movement to generate new solutions from the parameter space.
\item
  Use some set of rules to determine where to move next in the parameter space.
\item
  Declare convergence once some set of criteria has been met. Perhaps no improvement for X iterations.
\end{itemize}

\hypertarget{genetic-algorithm-and-simulated-annealing-as-examples}{%
\section{Genetic algorithm and simulated Annealing as examples}\label{genetic-algorithm-and-simulated-annealing-as-examples}}

\textbf{Genetic algorithm}: need to explore large portions of the parameter space at random. Concept of ``neighbor'' is vague.

\href{https://toddwschneider.com/posts/traveling-salesman-with-simulated-annealing-r-and-shiny/}{A nice shiny app}

An GA example: Since a new treatment for Hep C has become available, where is the optimal place to locate limited new Hep C resources, considering where our patients live?

The problem become intractable with large number of locations and resources: How many combinations of patients and clinics can I calculate the full feature space for to find a maximum?

\begin{itemize}
\tightlist
\item
  Exact Solution is NP-Hard
\item
  Calculations = \(n^{\sqrt{k}}\)
\item
  I conveniently stopped my analysis at 6 sites with \textasciitilde{}5k patients, requiring 1,149,712,053 distance calculations (I have a big server)
\item
  The ``k-center'' problem
\end{itemize}

\textbf{Simulated Annealing}:

\begin{itemize}
\tightlist
\item
  The concept of a `neighbor' is strong.
\item
  Can be sensitive to parameter choice, or algorithm gets stuck in global minima!
\item
  Generally, you should try both to see what works best. Hard to guess up front.
\end{itemize}

\hypertarget{constrains}{%
\section{Constrains}\label{constrains}}

Hard constraints

\begin{itemize}
\tightlist
\item
  If this constraint is violated, we have invalid solution.
\item
  Labor laws, number of nurses available, etc
\end{itemize}

Soft Constraints

\begin{itemize}
\tightlist
\item
  These are nice to meet if possible (included in cost function somehow), but if they are not met the solution is still valid.
\item
  Nurse prefers to only work X night shifts per month.
\item
  Leave requests.
\end{itemize}

\hypertarget{continuous-optimization}{%
\chapter{Continuous optimization}\label{continuous-optimization}}

Points to learn in continuous optimization:

\begin{itemize}
\tightlist
\item
  Understand first and second derivatives and the role they play in optimizing continuous functions.
\item
  Understand general steps in continuous optimization
\item
  Contrast 1st order versus 2nd order derivative optimization methods
\item
  Extend these thoughts to the distributed computing context
\end{itemize}

Things to consider for smart steps:

\begin{itemize}
\tightlist
\item
  Initialization value: where should I start?
\item
  Direction of the gradient: what direction should I we step towards?
\item
  Step size: how big of a step should we take?
\end{itemize}

\hypertarget{first-and-second-derivative-methods}{%
\section{First and second derivative methods}\label{first-and-second-derivative-methods}}

\textbf{First derivative/gradient}

\begin{itemize}
\tightlist
\item
  Instantaneous slope of a point (rate of change of the function)
\item
  If we have multiple input variables (multiple x's), then we need to know the gradient in the direction of each of the x's (partial derivatives). The matrix of partial first derivatives is called \textbf{the Jacobian}.
\end{itemize}

\textbf{Second derivative}

\begin{itemize}
\tightlist
\item
  Tells me the `curvature' of a function.
\item
  Rate of change of the first derivative.
\item
  If we have multiple input variables (multiple x's), then the matrix of partial second derivatives is called \textbf{the Hessian}.
\end{itemize}

A comparison of first and second order derivative methods

\begin{itemize}
\tightlist
\item
  Second order derivative methods are generally more accurate and converge in fewer steps
\item
  Second order derivative methods are more resource intensive
\item
  Sometimes it is easy and cheap to calculate the Hessian\ldots{}(generalized linear models with canonical link), so why not?
\item
  Sometimes it is expensive though.
\item
  There is a tradeoff here that is context dependent.
\end{itemize}

\textbf{Why not always second derivative}

\begin{itemize}
\tightlist
\item
  It's expensive and takes more time / resources / memory.
\item
  The Jacobian matrix only requires \(O(n)\) storage.
\item
  The Hessian matrix requires \(O(n^2)\) storage.
\item
  The size of the matrix grows exponentially with the size of the input data (specifically the number of columns).
\item
  But\ldots{}it can be more efficient if we take fewer steps, as long as the dataset isn't too big.
\end{itemize}

There is a tradeoff between the accuracy of the next step we take, and the amount of resources is take to calculate the next step.

\hypertarget{first-order-derivative-methods}{%
\section{First Order Derivative methods}\label{first-order-derivative-methods}}

\hypertarget{gradient-descent}{%
\subsection{Gradient descent}\label{gradient-descent}}

\href{https://en.wikipedia.org/wiki/Gradient_descent}{Sourced from wikipedia}

\begin{itemize}
\tightlist
\item
  Start somewhere (initial values for X)
\item
  Calculate the gradient at that point
\item
  Take a step in the correct direction based on the gradient
\item
  Step size is a function of the gradient (larger gradient means larger step size)
\item
  Repeat.
\item
  Stop algorithm once it converges (within tolerance) to a single point.
\item
  This is \textbf{expensive}! Requires a full pass over all training data at every step\ldots{}
\end{itemize}

\hypertarget{stochastic-gradient-descent}{%
\subsection{Stochastic gradient descent}\label{stochastic-gradient-descent}}

(\url{https://en.wikipedia.org/wiki/Stochastic_gradient_descent})

\begin{itemize}
\tightlist
\item
  Start somewhere (initial values for X)
\item
  Randomly shuffle the data by row.
\item
  For i=1,2,3\ldots{}n, calculate the gradient \textbf{only for the i'th sample} (not the full dataset).
\item
  Take a step in the correct direction based on the gradient
\item
  Step size is a function of the gradient (larger gradient means larger step size)
\item
  Repeat.
\item
  Stop algorithm once it converges (within tolerance) to a single point.
\item
  This is less costly, since you don't need a full pass over the data for every step. But it is less accurate as well\ldots{}
\end{itemize}

\hypertarget{coordinate-descent}{%
\subsection{Coordinate descent}\label{coordinate-descent}}

(\url{https://en.wikipedia.org/wiki/Coordinate_descent}

\begin{itemize}
\tightlist
\item
  If we have multiple X values, then we optimize them by only considering a change in a single X value at a time. The step size is based on only changing one X.
\item
  This is useful if it is hard to calculate the gradient for all variables (the Jacobian), but easier to only work on one variable at a time.
\item
  This is the optimal solver for regularized GLM's (elastic net regression).

  \begin{itemize}
  \tightlist
  \item
    Start somewhere (initial values for X)
  \item
    Choose one of the X's (coordinates), change the value (your step).
  \item
    Calculate the objective function. Next round, change a different X.
  \item
    Repeat.
  \item
    Stop algorithm once it converges (within tolerance) to a single point.
  \end{itemize}
\end{itemize}

Reference to \href{https://web.stanford.edu/~hastie/Papers/glmnet.pdf}{Regularization Paths for Generalized Linear Models via Coordinate Descent}

\hypertarget{second-order-derivative-methods}{%
\section{Second Order Derivative methods}\label{second-order-derivative-methods}}

\hypertarget{iteratively-reweighted-least-squares-irls}{%
\subsection{Iteratively reweighted least squares (IRLS)}\label{iteratively-reweighted-least-squares-irls}}

\begin{itemize}
\tightlist
\item
  This is the most popular in data science frameworks.
\item
  This is efficient and accurate for generalized linear models (logistic regression, Poisson regression etc\ldots{})
\item
  The Hessian matrix (second derivative) gives us information about the uncertainty of the solution. This is where our confidence intervals and p-values come from!
\end{itemize}

\hypertarget{newton-raphson-optimization-and-fisher-scoring}{%
\subsection{Newton-Raphson optimization and Fisher Scoring}\label{newton-raphson-optimization-and-fisher-scoring}}

\begin{itemize}
\tightlist
\item
  More general cases of IRLS. These are identical when applied to GLM's, so you often see the terms interchanged when talking about GLM's. These are not necessarily identical outside of GLM's.
\item
  Second-order methods are sometimes termed `Newton methods'
\end{itemize}

\hypertarget{limited-memory-broyden-fletcher-goldfarb-shanno-l-bfgs}{%
\subsection{Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS)}\label{limited-memory-broyden-fletcher-goldfarb-shanno-l-bfgs}}

Technically first order since it does not evaluate the Hessian.

\begin{itemize}
\tightlist
\item
  However, it does approximate the Hessian by storing the prior gradient evaluations!
\item
  So we get some idea of the rate of change of the gradient by looking at the trend of the prior gradients.
\item
  This is termed `quasi-Newton' since we approximate the Hessian without actually incurring the full cost
\end{itemize}

Orthant-Wise Limited-memory Quasi-Newton (OWL-QN) is an extension to this that effectively optimizes regularized regression (L1 or elastic net). This is implemented in Apache Spark.

\hypertarget{l-bfgs-versus-irls-for-glms}{%
\subsection{L-BFGS Versus IRLS for GLM's}\label{l-bfgs-versus-irls-for-glms}}

\begin{itemize}
\tightlist
\item
  Both can be implemented in parallel by calculating chunks of rows at a time.
\item
  Consider m rows and n columns\ldots{}the IRLS algorithm requires an NxN matrix be generated no matter how small we make M by chunking by row.
\item
  So if we have a large number of columns, IRLS can underperform (take too long / too much memory), even in distributed environments.
\item
  L-BFGS is more efficient for a large number of columns. But, it is generally less accurate (Takes more steps).
\end{itemize}

\hypertarget{close-thoughts}{%
\section{Close thoughts}\label{close-thoughts}}

\begin{itemize}
\tightlist
\item
  Choice of optimization method is important!
\item
  Depending on how large your data is, or how complex your objective function is, you may have to try different optimization methods.
\item
  If the optimization method you choose does not give you estimates about the uncertainty of the solution (I.E. confidence intervals and p-values), you may be able to get that from a direct Hessian calculation once you have declared the optimal solution to be found.
\end{itemize}

\hypertarget{machine-learning-basics}{%
\chapter{Machine learning basics}\label{machine-learning-basics}}

\begin{quote}
Machine learning is essentially a form of applied statistics with increased emphasis on the use of computers to statistically estimate complicated functions and a decreased emphasis on proving confidence intervals around those functions
\end{quote}

\begin{quote}
-- Deep Learning Book
\end{quote}

\begin{itemize}
\tightlist
\item
  Using data, develop a `learning algorithm' (our model).
\item
  Often the focus is prediction of an outcome, given inputs.
\item
  Finding patterns in the data versus finding generalizable trends in the data.
\end{itemize}

\hypertarget{what-do-we-need-to-develop-a-learning-algorithm}{%
\section{What do we need to develop a learning algorithm?}\label{what-do-we-need-to-develop-a-learning-algorithm}}

\begin{itemize}
\tightlist
\item
  Data
\item
  Model
\item
  Cost function
\item
  Optimization function
\end{itemize}

\hypertarget{classification-regression-and-clustering}{%
\section{Classification, regression, and clustering}\label{classification-regression-and-clustering}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Classification
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Predicting class membership (or probabilities) among distinct classes.
\item
  Death (Yes / No)
\item
  Risk Strata (Low / Medium / High)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Regression
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Predicting a continuous summary statistic (like the mean)
\item
  Hospital cost (Mean, median, 90th percentile)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Clustering
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Identifying clusters in our data.
\item
  Project data into smaller dimensionality.
\item
  Clustering can be discrete or continuous.
\end{itemize}

Central challenge to ML: \textbf{generalization}.

The algorithm must perform well on new data it has never seen before

\begin{itemize}
\tightlist
\item
  Next years data
\item
  New healthcare system
\item
  New patients
\end{itemize}

\hypertarget{underoverfitting-and-out-of-sample-data}{%
\section{Under/overfitting and out of sample data}\label{underoverfitting-and-out-of-sample-data}}

Given the data we have, how good is our model?

\begin{itemize}
\tightlist
\item
  This is really just optimization.
\item
  \emph{Training error} is how well we fit the training data.
\item
  Increased performance here sometimes decreases performance outside of our sample of data (\emph{overfitting})
\end{itemize}

In ML, we target generalization error

\begin{itemize}
\tightlist
\item
  \emph{Generalization error} is how well our algorithm fits data outside our sample.
\item
  But we don't have any data outside our sample\ldots{}
\item
  Can we pretend we do?
\end{itemize}

\hypertarget{validation-approaches}{%
\section{Validation approaches}\label{validation-approaches}}

\begin{itemize}
\tightlist
\item
  If the new data does not come from the same data-generating distribution as the observed data, full stop.
\item
  If we assume the new data comes from the same data-generating distribution, then we can implement validation approaches.

  \begin{itemize}
  \tightlist
  \item
    Create multiple random samples from the data we have
  \item
    Call one `training data' and one `Validation' data.
  \item
    Actually we usually split into training / validation / testing (3 splits).
  \end{itemize}
\item
  Optimization goal:

  \begin{itemize}
  \tightlist
  \item
    Minimize training error (high error = underfitting)
  \item
    Minimize gap between training and testing error (big gap = overfitting)
  \end{itemize}
\end{itemize}

Creative Validation Approaches:

\begin{itemize}
\tightlist
\item
  Splitting by clusters.

  \begin{itemize}
  \tightlist
  \item
    Split by year, region, etc
  \end{itemize}
\item
  Cross validation
\end{itemize}

Balancing under and overfitting:

\begin{itemize}
\tightlist
\item
  We can balance under and overfitting by making our model more/less complex. The deep learning book calls this \textbf{model capacity}
\item
  Increasing model capacity generally allows the model to fit more nuanced relationships.

  \begin{itemize}
  \tightlist
  \item
    In linear modeling -- add more inputs, consider non-linear terms (polynomials), consider interactions\ldots{}
  \end{itemize}
\item
  What is the downside of increased model capacity?
\end{itemize}

Model parsimony

\begin{quote}
Among competing hypotheses that explain known observations equally well, choose the simplest one.
\end{quote}

\begin{quote}
\begin{itemize}
\tightlist
\item
  Occam's razor (c.~1287-1347)
\end{itemize}
\end{quote}

\hypertarget{regularization}{%
\section{Regularization}\label{regularization}}

\begin{itemize}
\tightlist
\item
  Hard code preferences into the model.

  \begin{itemize}
  \tightlist
  \item
    I prefer Beta's close to or equal to zero (parsimony)
  \item
    However, if I find enough support for a relationship, it can stay.
  \item
    How to I hard code that into my model?
  \item
    What is an example you have learned of this in ML?
  \end{itemize}
\end{itemize}

\begin{quote}
\textbf{Regularization} is any modification we make to a learning algorithm that is intended to reduce its \textbf{generalization error not it's training error}.'
\end{quote}

\hypertarget{hyperparameter-tuning}{%
\section{Hyperparameter tuning}\label{hyperparameter-tuning}}

\begin{itemize}
\tightlist
\item
  Hyperparameters are `knobs' we can use to tune an ML algorithm
\item
  We do not learn these from the training data, because\ldots{}

  \begin{itemize}
  \tightlist
  \item
    It is too hard/impossible to optimize them directly OR
  \item
    Their intent is to decrease generalization error (not training error), so it is not appropriate to learn them from the training data. Why is this true?
  \end{itemize}
\item
  We often have multiple hyperparameters, and wish to tune across all of them. This is referred to as the `hyperparameter grid'.
\end{itemize}

\hypertarget{binary-classification-models-in-scikit-learn}{%
\section{Binary classification models in scikit-learn}\label{binary-classification-models-in-scikit-learn}}

\begin{itemize}
\tightlist
\item
  Logistic regression
\item
  Elastic net logistic regression (regularized)
\item
  Support Vector Machine
\item
  General SGD estimation (sklearn), it can specify different loss functions
\item
  Nearest neighbor majority vote (non-parametric)
\item
  Random forests

  \begin{itemize}
  \tightlist
  \item
    Fully grown trees (not weak learners). Low bias, high variance per tree
  \item
    Grow many trees (maybe in parallel?) to reduce variance.
  \end{itemize}
\item
  Gradient boosting machine

  \begin{itemize}
  \tightlist
  \item
    Forest of weak learner trees (high bias, low variance)
  \item
    Correct bias each new sequence.
  \item
    Sequential method!
  \end{itemize}
\end{itemize}

\hypertarget{mcmc-and-variational-inference}{%
\chapter{MCMC and variational inference}\label{mcmc-and-variational-inference}}

In MCMC, we construct ergodic Markov chains whose stationary distribution is the posterior distribution. Instead of using \textbf{sampling}, variational inference uses \textbf{optimization} to approximate the posterior distribution, which is better suited when applied to large data or complex models.

MCMC and VI are different approaches to solve the sample question. MCMC is more computationally intensive but guarantees producing exact samples from the target density (it is guaranteed to find a global optimal solution\footnote{\url{https://ermongroup.github.io/cs228-notes/inference/variational/}}). VI takes advantage of methods such as stochastic optimization and distributed optimization, so it is preferred if we want to fit model to a large dataset. VI will almost never find the globally optimal solution, but we will always know if it converged, and we will hav bounds on its accuracy.

\hypertarget{mcmc}{%
\section{MCMC}\label{mcmc}}

\hypertarget{variational-inference}{%
\section{Variational inference}\label{variational-inference}}

Variational inference (VI) first posits a family of densities, and then find a member of that family that is close to the target density, where the closeness is evaluated by Kullback--Leibler divergence \citep{blei2017variational}. Compared with MCMC, VI methods tends to be faster and easier to use in terms of large data, but it generally \textbf{underestimates} the variance of the posterior density due as a consequence of its objective function.

Steps to perform VI:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  posit a family of approximate densities \(Q\)
\item
  find a member of that family that minimizes the Kullback-Leibler (KL) divergence to the exact posterior
\item
  approximate the posterior with the optimized member of the family \(q^{\star}(.)\).
\end{enumerate}

The KL divergence of two distributions \(q\) and \(p\) with discrete support is:

\[KL(q||p) = \sum_xq(x)\log \frac{q(x)}{p(x)}\]

One of the key ideas behind VI is to choose \(Q\) to be \emph{flexible enough} to capture a density close to \(p(\theta|x)\), but \emph{simple enough} for efficient optimization.

The aims of modern VI:

\begin{itemize}
\tightlist
\item
  tackling Bayesian inference problems that involve massive data,
\item
  using improved optimization methods for solving equation 1, which is ususally subject to local minima,
\item
  develop generic VI algorithms that apply to a wide class of models
\item
  increase the accuracy of VI
\end{itemize}

\textbf{Mean-field VI}

\textbf{coordinate-ascent optimization}

\textbf{stochastic VI}

\hypertarget{undecided}{%
\chapter{undecided}\label{undecided}}

\bibliography{bib/bib.bib}


\backmatter
\printindex

\end{document}
