# Notes on machine learning algorithms


## Discrete optimization

- Heuristic and meta-heuristic methods
- Genetic algorithms and simulated annealing as examples
- constrains

## Continuous optimization

- First and second order derivative methods
- First order methods: gradient descent, stochastic gradient descent, and coordinate descent
- Second order methods: IRLS, Newton-Raphson, Fisher scoring, L-BFGS

## ML basics

- Classification, regression, and clustering
- Under/overfitting and out-of-sample data
- Validation approaches
- Regularization
- Hyperparameter tuning
- Binary classification and models in scikit-learning

## Bayesian estimation

- MCMC
  + data subsampling
  + diverse array of strategies to scale out on parallel resources
- Variational inference
  + stochastic gradient optimization
  + incremental posterior updating
